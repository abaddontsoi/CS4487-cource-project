{"cells":[{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11185,"status":"ok","timestamp":1764601237183,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"5QEw7pzlPbwZ","outputId":"c067c17c-fa52-49c8-bb75-b3a16dbc933b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting git+https://github.com/openai/CLIP.git\n","  Cloning https://github.com/openai/CLIP.git to /tmp/pip-req-build-b_zfvj70\n","  Running command git clone --filter=blob:none --quiet https://github.com/openai/CLIP.git /tmp/pip-req-build-b_zfvj70\n","  Resolved https://github.com/openai/CLIP.git to commit dcba3cb2e2827b402d2701e7e1c7d9fed8a20ef1\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (6.3.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (25.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2025.11.3)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (4.67.1)\n","Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from clip==1.0) (0.24.0+cu126)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->clip==1.0) (0.2.14)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->clip==1.0) (3.5.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->clip==1.0) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->clip==1.0) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->clip==1.0) (3.0.3)\n","Requirement already satisfied: open_clip_torch in /usr/local/lib/python3.12/dist-packages (3.2.0)\n","Requirement already satisfied: torch>=2.0 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2.9.0+cu126)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.24.0+cu126)\n","Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (2025.11.3)\n","Requirement already satisfied: ftfy in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (6.3.1)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (4.67.1)\n","Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.36.0)\n","Requirement already satisfied: safetensors in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (0.7.0)\n","Requirement already satisfied: timm>=1.0.17 in /usr/local/lib/python3.12/dist-packages (from open_clip_torch) (1.0.22)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from timm>=1.0.17->open_clip_torch) (6.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.20.0)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.14.0)\n","Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.6)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.1.6)\n","Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (2.27.5)\n","Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.3.20)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0->open_clip_torch) (3.5.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy->open_clip_torch) (0.2.14)\n","Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (25.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (2.32.4)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub->open_clip_torch) (1.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (2.0.2)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->open_clip_torch) (11.3.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0->open_clip_torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0->open_clip_torch) (3.0.3)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.4.4)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (3.11)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->huggingface-hub->open_clip_torch) (2025.11.12)\n"]}],"source":["!pip install git+https://github.com/openai/CLIP.git\n","!pip install open_clip_torch"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1764601237194,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"jTVyXFHQCP8f"},"outputs":[],"source":["import os\n","import pandas as pd\n","from PIL import Image\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms\n","from tqdm import tqdm\n","import open_clip\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\""]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11776,"status":"ok","timestamp":1764601500650,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"ngcn0MRyCP8h","outputId":"69efc4c6-c02e-4730-b8b1-98ceaf37cb9c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n","Loading processor: openai/clip-vit-base-patch32...\n","Initializing model architecture...\n","Loading weights from clip_aigc_detector.pth...\n","Starting inference on 2500 images...\n"]},{"name":"stderr","output_type":"stream","text":["Predicting: 100%|██████████| 20/20 [00:05<00:00,  3.35it/s]"]},{"name":"stdout","output_type":"stream","text":["\n","Success! submission.csv saved with 2500 rows.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["import os\n","import torch\n","import torch.nn as nn\n","from torch.utils.data import Dataset, DataLoader\n","from PIL import Image\n","import pandas as pd\n","from tqdm import tqdm\n","from transformers import CLIPVisionModel, AutoProcessor\n","\n","# -------------------------------------------------\n","# 1. Configuration & Setup\n","# -------------------------------------------------\n","MODEL_NAME = \"openai/clip-vit-base-patch32\"\n","MODEL_PATH = \"clip_aigc_detector.pth\"\n","TEST_DIR = \"./test\"\n","OUTPUT_CSV = \"submission.csv\"\n","BATCH_SIZE = 128\n","DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","\n","# -------------------------------------------------\n","# 2. The Model Architecture (Fixed Dimensions)\n","# -------------------------------------------------\n","class AIGCDetector(nn.Module):\n","    def __init__(self, base_model_name):\n","        super().__init__()\n","        self.backbone = CLIPVisionModel.from_pretrained(base_model_name)\n","\n","        # Freeze backbone\n","        for param in self.backbone.parameters():\n","            param.requires_grad = False\n","\n","        # FIX: The error showed the saved weight was [1, 512].\n","        # This means the final layer must be Linear(512, 1).\n","        self.classifier = nn.Sequential(\n","            nn.Linear(768, 512),\n","            nn.ReLU(),\n","            nn.Dropout(0.1),\n","            nn.Linear(512, 1)  # <--- Changed from 2 to 1\n","        )\n","\n","    def forward(self, pixel_values):\n","        outputs = self.backbone(pixel_values=pixel_values)\n","        features = outputs.pooler_output\n","        logits = self.classifier(features)\n","        return logits\n","\n","# -------------------------------------------------\n","# 3. Test Dataset\n","# -------------------------------------------------\n","class TestDataset(Dataset):\n","    def __init__(self, test_dir, processor):\n","        self.test_dir = test_dir\n","        self.processor = processor\n","        self.files = sorted([\n","            f for f in os.listdir(test_dir)\n","            if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp', '.tiff', '.webp'))\n","        ])\n","\n","    def __len__(self):\n","        return len(self.files)\n","\n","    def __getitem__(self, idx):\n","        file_name = self.files[idx]\n","        path = os.path.join(self.test_dir, file_name)\n","        image = Image.open(path).convert(\"RGB\")\n","\n","        # Preprocess\n","        inputs = self.processor(images=image, return_tensors=\"pt\")\n","        pixel_values = inputs['pixel_values'].squeeze(0)\n","\n","        img_id = file_name.rsplit(\".\", 1)[0]\n","        return pixel_values, img_id\n","\n","# -------------------------------------------------\n","# 4. Main Execution\n","# -------------------------------------------------\n","def test_model():\n","    if not os.path.exists(MODEL_PATH):\n","        raise FileNotFoundError(f\"Model weights not found at {MODEL_PATH}\")\n","    if not os.path.exists(TEST_DIR):\n","        raise FileNotFoundError(f\"Test folder not found at {TEST_DIR}\")\n","\n","    print(f\"Using device: {DEVICE}\")\n","\n","    # 1. Initialize Processor\n","    print(f\"Loading processor: {MODEL_NAME}...\")\n","    processor = AutoProcessor.from_pretrained(MODEL_NAME)\n","\n","    # 2. Initialize Model\n","    print(\"Initializing model architecture...\")\n","    model = AIGCDetector(MODEL_NAME).to(DEVICE)\n","\n","    # 3. Load Weights\n","    print(f\"Loading weights from {MODEL_PATH}...\")\n","    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n","\n","    # We load the state dict directly. The error confirmed the keys match\n","    # the full model structure (backbone + classifier).\n","    model.load_state_dict(state_dict)\n","    model.eval()\n","\n","    # 4. Prepare DataLoader\n","    test_dataset = TestDataset(TEST_DIR, processor)\n","    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False,\n","                             num_workers=4, pin_memory=True)\n","\n","    print(f\"Starting inference on {len(test_dataset)} images...\")\n","\n","    results = []\n","\n","    with torch.no_grad():\n","        for pixel_values, ids in tqdm(test_loader, desc=\"Predicting\"):\n","            pixel_values = pixel_values.to(DEVICE)\n","\n","            # Forward pass\n","            logits = model(pixel_values) # Shape: (Batch_Size, 1)\n","\n","            # FIX: Use Sigmoid for single-output binary classification\n","            probs = torch.sigmoid(logits).view(-1) # Flatten to (Batch_Size,)\n","\n","            # Thresholding\n","            preds = (probs > 0.5).int()\n","\n","            for img_id, pred in zip(ids, preds.cpu().tolist()):\n","                results.append({\"ID\": img_id, \"label\": pred})\n","\n","    # 5. Save Submission\n","    df = pd.DataFrame(results)\n","    df = df.sort_values(\"ID\").reset_index(drop=True)\n","    df.to_csv(OUTPUT_CSV, index=False)\n","\n","    print(f\"\\nSuccess! {OUTPUT_CSV} saved with {len(df)} rows.\")\n","\n","if __name__ == \"__main__\":\n","    test_model()"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1764601505243,"user":{"displayName":"abaddon MR","userId":"15509689131894001305"},"user_tz":-480},"id":"jicsK-acCP8i"},"outputs":[],"source":["data_root = \"path_to_dataset\"\n","model_path = \"saved_model.pth\""]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"L4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
